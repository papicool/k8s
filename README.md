# k8s

1.1 Understanding Cloud Computing

- In this lesson I would like to tell you about cloud computing. So what is it all about? Well, cloud has emerged as a standard platform for running applications, where in the old days you will be running your applications directly on top of an operating system. Now the cloud has taken over much of the functionality of an operating system. And doing so brings multiple benefits. For one, the underlying platform is easily scaled. So if you need more capacity, you can easily add capacity, as it's available virtually unlimited in cloud. Also because of the scalability of the platform the application itself can be scaled easily, manually, as well as automatically. So if suddenly the demand on your web shop triples, well you can have a configuration that automatically triples the availability of your application as well. Cloud can be offered as a worldwide platform and that ensures that applications are accessible anywhere. And nowadays that so many companies are providing access to their application on smartphone platforms, it's just a perfect solution to make sure that no matter where on the world your users are, they can use your application. And also, applications don't have a direct relation with any specific server. That's what call decoupling. And that's a benefit, because it means that if your server goes down your application can still continue functioning. Now, cloud as search offer stateful APIs and that allows new IT strategies such as DevOps and GitOps and CI/CD. These are strategies that you may have heard about and which we'll see to some extent in further lessons in this course. Also, cloud offers standardization and that makes it easy to deploy applications on no matter which platform. So let's talk about cloud computing some more. In public cloud, resources can be hired as needed and the cloud provider takes care of the underlying infrastructure. So that means that you don't need an IT department anymore you just need a public cloud platform. In private cloud, a company can use its own infrastructure to offer cloud services. And regardless which type of cloud is used, behind the cloud are always physical or virtual servers hosting the application workload. But again, the physical or virtual service are decoupled. As a user of cloud, you don't deal with them directly anymore. And the result is that the application also doesn't have any relation with the service anymore. And that's a big thing in Kubernetes. We will see it throughout the course. To facilitate all of this, the cloud must offer facilities to store application resources in cloud. And that is something you'll learn more about in the next couple of lessons.


1.2 Running Applications in Cloud


- So what is the challenge in a cloud environment? Well, the cloud is something untouchable, right? And the thing with cloud is that you are running on different servers but these servers are kind of invisible. It's really the cloud that your application is going to interact with. So if you have your application right here it must be using resources that are in the cloud in a decoupled way. Decoupled means that the application cannot have a direct relation with the server. Now, there is a small challenge because applications need site specific information. Think of environment variables, think of configuration and challenges? How are we going to store all of that in the cloud? Well, that is what is provided by the Cloud API. The Cloud API defines different

1.3 Why Containers Make Sense in Cloud Environments


  - In this video, we'll talk about a role of containers in cloud environments. So to start with, let's talk about microservices which are closely related to containers. Microservices allow for efficient application development and maintenance. In microservices, different application components are connected to each other, and the individual microservices components are offered as containers. So what exactly is a container? Well, a container is started from an image. And the image is configured with the default application. That's what we call the entrypoint application. Inside the image, all libraries that are needed to start the application are included. And to run a container, you will need a container runtime. The container runtime is a platform-independent component that is use certain containers. Runtimes are standardized in a container runtime interface, also known as a CRI. And commonly used container runtimes are containerd and cri-o. Runtimes allow containers to be started on any operating system or cloud platform. And if you are using Kubernetes, the runtime is integrated in Kubernetes. If you are using standalone containers such as Docker or PopMan, the runtime is integrated in either Docker or PopMan. But using a runtime, it's a foundation for running containers in a Kubernetes environment.

1.4 The Rise of Kubernetes


- In this video, we'll talk about the rise of Kubernetes. So you can understand Kubernetes if you know what a container needs are in a cloud environment. If you want to run applications successfully in cloud, specific features need to be added. And these include scalability. That's the ability to automatically add capacity to your application. And availability, which means that if anything goes wrong with your application and it goes down, it's automatically started again. And also zero-downtime application updates, which is pretty cool because it means that you can update your application without bringing down the application. So the user will have the benefit of continuous application availability. Also, you need a framework to store application specific information in cloud. Now, why is that? That is because you need an alternative for the good OLT configuration file, for instance. If you have server-based computing, everything is stored in files. In cloud, there's no notion of a file because a file is connected to individual servers. And for that reason, in cloud, you need to do it differently. Now, Kubernetes has become the de-facto standard for running applications in cloud, for the simple reason that it is offering all of these features. Now, where does Kubernetes come from? Kubernetes is based on Google Borg. Borg is the internal system that Google had used for over a decade before releasing the Borg source code and specification. In April 2015, Google published an article about the insides of Borg, and you can find it on the link that is on the slide. Now, following that article, Google donated the Borg source code to Cloud Native Computing Foundation, or CNCF. CNCF is a foundation within Linux Foundation which is taking care of protecting the open source nature of Kubernetes, and also of building an ecosystem around Kubernetes that's all about Cloud Native Applications. This is what we consider the start of Kubernetes. Now, by donating the Kubernetes source code to CNCF, it is guaranteed to be open source forever, for the simple reason that CNCF is part of Linux Foundation, and they have a long experience already as an open source company. The result is that any company can develop solutions on top of Kubernetes, and that makes Kubernetes a commodity layer available to anyone. So the result is that nobody has to worry about developing this common layer anymore, but companies can focus on solutions that run on top of Kubernetes. So the result of this open source effort where everybody is working together is a higher quality platform because the base layer is freely available.

1.5 The Kubernetes Ecosystem

- So Kubernetes doesn't stand on its own. Around Kubernetes, there's a complete ecosystem. CNCF is the owner of the core Kubernetes packages. That's what we also know as vanilla Kubernetes. Specific functionality is provided by open-source products and companies, which we refer to as the ecosystem. So to build a complete Kubernetes solution, you need vanilla Kubernetes plus solutions from the ecosystem. Think about solutions about networking or storage or observability or ingress or service mesh. CNCF does not have a preference for any ecosystem solution. They just provide the ecosystem and leave it up to the users to decide what they want to use. If you are installing vanilla Kubernetes, ecosystem components need to be added to get a fully working solution. Let's have a look at some of these ecosystem components. So here we have the cncf.io website where you can find more information about Cloud Native Computing Foundation. As you can see, 134 projects in total. And in case you are wondering, what are all these happy people? Well, these happy people are people that have visited KubeCon. KubeCon is the major Kubernetes conference that CNCF is organizing. So here we have the CNCF projects. And if you click on that link, then you can see that there are multiple products that are available: graduated and incubated and sandbox and archived indicates the status of the project. Where graduated means that the product is fully operational. Incubating means that it has recently been created and people are using it. Sandbox means it's new. And archived is for old project. You wanna see which project currently are graduated? There we go. Here's a complete list of all the graduated projects in which you can find Kubernetes itself. But for instance, also software like Helm, which is for building applications. This, in fact, is a Kubernetes package manager or a Rook, the Kubernetes storage solution. It's a good idea to have a look at all the different projects that are available on CNCF because it's giving quite a good impression of what is going on and which products are really considered ready to use. Now with all these different projects, it can be difficult for an end user to make a choice of what to use and that is where the Kubernetes distributions come in. So Kubernetes distributions combine core vanilla Kubernetes with solutions from the ecosystem, and that is bundled together and offered by the distribution where support is provided as well. Some distributions are, as they call it, opinionated. Opinionated means that they just offer one specific solution for each component in the ecosystem. So it's not up to you to choose which network agent you are going to use but the distribution will make that choice for you. Other distributions are non-opinionated and they offer a choice of multiple solutions. And in case you are wondering, why do distributions deliver opinionated solutions? Well, in an opinionated solution, the support company only has to focus on one specific product and that makes it easier to deliver good quality support. Now, Kubernetes distributions themselves are available for using cloud, on premise, or in minimized learning environments. Let's have a look at some common Kubernetes distributions. These include Rancher, currently owned by SUSE, commonly used for on premise installations. Or Canonical Kubernetes, which can also be used for on premise installations, and likewise for Google Anthos. Then there is Red Hat OpenShift, a Kubernetes distribution where Red Hat has added many operators to provide developer functionality, so it's very oriented on the DevOps workflow. GKE, which is the Google cloud-based Kubernetes solution. Or AKS and EKS, for Azure and Amazon integrated Kubernetes, which you will find in their public cloud solutions. And there is Minikube. Minikube, which is a perfect learning solution, which works as an all-in-one solution that you can install on top of any operating system you might be using; and as Kind, Kubernetes in Docker. And apart from that, there are many more. It's not my intention here to list all of the Kubernetes distributions. The intention in this course is to make sure that you are familiar with Kubernetes generically. For that reason, I'm going to show you how to work with Minikube and a couple of other solutions as well. But Minikube is really the best platform for learning Kubernetes. I'll tell you later how to get started with it. For now, let's continue with the next lesson which is about standardization.


1.6 Standardization in Cloud Native Computing


- In this video, we'll talk about Standardization in Cloud Native Computing environments. So there is the Open Containers Initiative, or OCI. This initiative was created by Docker in 2015 to ensure that common standards are used in the world of containers. One example of a common standard that it has produced is a container image format. As container solutions are highly standardized, transition from one container stack to another is made easy. Because of this OCI, it is, for instance, very easy to transition from Docker containers to Podman containers, because the images that are used in one solution can be used without any modifications in the other solution. There's also CNCF, the Cloud Native Computing Foundation. So CNCF is a foundation within Linux Foundation, and they are the owner of the Kubernetes source code. CNCF provides guidelines for different products in the Kubernetes ecosystem, and they also have released a few standards like the CNI, which is a Container Network Interface, or the CRI, which is a Container Runtime Interface, and the CSI, which is a Container Storage Interface. And by using all these common solutions, we obtain the awesome goal of compatibility and easiness to work with different solutions and to move from one solution to another. Another thing that I would like to talk about is Kubernetes certification. CNCF offers certification in Kubernetes to professionals who want to validate their skills. It starts with Kubernetes and Cloud Native Associate. This is an entry level certification about Kubernetes and Cloud Native core components, and it's based on a multiple-choice exam. There is a Certified Kubernetes Application Developer, or CKAD, that is a hands-on exam that focuses on running applications in Kubernetes. There is also Certified Kubernetes Administrator, which also is a hands-on exam that focuses on managing Kubernetes applications and clusters. And lastly, there is Certified Kubernetes Security, which also is a hands-on exam that focuses on securing applications in Kubernetes. So as you can see, if you want to distinguish yourself, then there's a lot of certifications to obtain. Apart from that, Cloud Native Computing Foundation is also hosting other certifications for different products that are hosted by the CNCF.
